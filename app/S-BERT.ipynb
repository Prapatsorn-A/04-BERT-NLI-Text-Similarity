{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Sentence-BERT](https://arxiv.org/pdf/1908.10084.pdf)\n",
    "\n",
    "[Reference Code](https://www.pinecone.io/learn/series/nlp/train-sentence-transformers-softmax/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import re\n",
    "from   random import *\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Set GPU device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "os.environ['http_proxy']  = 'http://192.41.170.23:3128'\n",
    "os.environ['https_proxy'] = 'http://192.41.170.23:3128'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Test, Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'premise': Value(dtype='string', id=None),\n",
       "  'hypothesis': Value(dtype='string', id=None),\n",
       "  'label': ClassLabel(names=['entailment', 'neutral', 'contradiction'], id=None),\n",
       "  'idx': Value(dtype='int32', id=None)},\n",
       " {'premise': Value(dtype='string', id=None),\n",
       "  'hypothesis': Value(dtype='string', id=None),\n",
       "  'label': ClassLabel(names=['entailment', 'neutral', 'contradiction'], id=None)})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "# Load SNLI and MNLI datasets\n",
    "snli = datasets.load_dataset('snli')\n",
    "mnli = datasets.load_dataset('glue', 'mnli')\n",
    "\n",
    "# View features of the train split for both datasets\n",
    "mnli['train'].features, snli['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'validation_matched', 'validation_mismatched', 'test_matched', 'test_mismatched'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of datasets to remove 'idx' column from\n",
    "mnli.column_names.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'idx' column from each dataset\n",
    "for column_names in mnli.column_names.keys():\n",
    "    mnli[column_names] = mnli[column_names].remove_columns('idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'validation_matched', 'validation_mismatched', 'test_matched', 'test_mismatched'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli.column_names.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([-1,  0,  1,  2]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(mnli['train']['label']), np.unique(snli['train']['label'])\n",
    "#snli also have -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are -1 values in the label feature, these are where no class could be decided so we remove\n",
    "snli = snli.filter(\n",
    "    lambda x: 0 if x['label'] == -1 else 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([0, 1, 2]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(mnli['train']['label']), np.unique(snli['train']['label'])\n",
    "#snli also have -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming you have your two DatasetDict objects named snli and mnli\n",
    "from datasets import DatasetDict\n",
    "# Merge the two DatasetDict objects\n",
    "raw_dataset = DatasetDict({\n",
    "    'train': datasets.concatenate_datasets([snli['train'], mnli['train']]).shuffle(seed=55).select(list(range(1000))),\n",
    "    'test': datasets.concatenate_datasets([snli['test'], mnli['test_mismatched']]).shuffle(seed=55).select(list(range(100))),\n",
    "    'validation': datasets.concatenate_datasets([snli['validation'], mnli['validation_mismatched']]).shuffle(seed=55).select(list(range(1000)))\n",
    "})\n",
    "# Remove .select(list(range(1000))) in order to use full dataset\n",
    "# Now, merged_dataset_dict contains the combined datasets from snli and mnli\n",
    "raw_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load pre-trained BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    max_seq_length = 128\n",
    "    padding = 'max_length'\n",
    "    # Tokenize the premise\n",
    "    premise_result = tokenizer(\n",
    "        examples['premise'], padding=padding, max_length=max_seq_length, truncation=True)\n",
    "    #num_rows, max_seq_length\n",
    "    # Tokenize the hypothesis\n",
    "    hypothesis_result = tokenizer(\n",
    "        examples['hypothesis'], padding=padding, max_length=max_seq_length, truncation=True)\n",
    "    #num_rows, max_seq_length\n",
    "    # Extract labels\n",
    "    labels = examples[\"label\"]\n",
    "    #num_rows\n",
    "    return {\n",
    "        \"premise_input_ids\": premise_result[\"input_ids\"],\n",
    "        \"premise_attention_mask\": premise_result[\"attention_mask\"],\n",
    "        \"hypothesis_input_ids\": hypothesis_result[\"input_ids\"],\n",
    "        \"hypothesis_attention_mask\": hypothesis_result[\"attention_mask\"],\n",
    "        \"labels\" : labels\n",
    "    }\n",
    "\n",
    "tokenized_datasets = raw_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    ")\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(['premise','hypothesis','label'])\n",
    "tokenized_datasets.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['premise_input_ids', 'premise_attention_mask', 'hypothesis_input_ids', 'hypothesis_attention_mask', 'labels'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['premise_input_ids', 'premise_attention_mask', 'hypothesis_input_ids', 'hypothesis_attention_mask', 'labels'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['premise_input_ids', 'premise_attention_mask', 'hypothesis_input_ids', 'hypothesis_attention_mask', 'labels'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# initialize the dataloader\n",
    "batch_size = 16\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets['train'], \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets['validation'], \n",
    "    batch_size=batch_size\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    tokenized_datasets['test'], \n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 128])\n",
      "torch.Size([16, 128])\n",
      "torch.Size([16, 128])\n",
      "torch.Size([16, 128])\n",
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    print(batch['premise_input_ids'].shape)\n",
    "    print(batch['premise_attention_mask'].shape)\n",
    "    print(batch['hypothesis_input_ids'].shape)\n",
    "    print(batch['hypothesis_attention_mask'].shape)\n",
    "    print(batch['labels'].shape)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self, vocab_size, max_len, n_segments, d_model, device):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.tok_embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_embed = nn.Embedding(max_len, d_model)\n",
    "        self.seg_embed = nn.Embedding(n_segments, d_model)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, x, seg):\n",
    "        \n",
    "        # Check for invalid indices in x (input_ids)\n",
    "        if (x < 0).any() or (x >= self.tok_embed.num_embeddings).any():\n",
    "            raise ValueError(\"input_ids contains invalid indices.\")\n",
    "        \n",
    "        # Check for invalid indices in seg (segment_ids)\n",
    "        if (seg < 0).any() or (seg >= self.seg_embed.num_embeddings).any():\n",
    "            raise ValueError(\"segment_ids contains invalid indices.\")\n",
    "\n",
    "        seq_len = x.size(1)\n",
    "        pos = torch.arange(seq_len, dtype=torch.long).to(self.device)\n",
    "        pos = pos.unsqueeze(0).expand_as(x)\n",
    "        embedding = self.tok_embed(x) + self.pos_embed(pos) + self.seg_embed(seg)\n",
    "        return self.norm(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_pad_mask(seq_q, seq_k, device, attention_mask=None):\n",
    "    if attention_mask is not None:\n",
    "        # Use the provided attention_mask and convert to boolean\n",
    "        pad_attn_mask = attention_mask.unsqueeze(1).expand(-1, seq_q.size(1), -1).to(device)\n",
    "        pad_attn_mask = ~pad_attn_mask.bool()  # Invert to match PyTorch's convention\n",
    "    else:\n",
    "        # Fallback to the original behavior: mask where seq_k is 0 (padding)\n",
    "        pad_attn_mask = seq_k.data.eq(0).unsqueeze(1).to(device)\n",
    "        pad_attn_mask = pad_attn_mask.expand(seq_q.size(0), seq_q.size(1), seq_k.size(1))\n",
    "    return pad_attn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, n_heads, d_model, d_ff, d_k, device):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.enc_self_attn = MultiHeadAttention(n_heads, d_model, d_k, device)\n",
    "        self.pos_ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "    def forward(self, enc_inputs, enc_self_attn_mask):\n",
    "        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask)\n",
    "        enc_outputs = self.pos_ffn(enc_outputs)\n",
    "        return enc_outputs, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, d_k, device):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([d_k])).to(device)\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)) / self.scale\n",
    "        scores.masked_fill_(attn_mask, -1e9)  # attn_mask must be boolean\n",
    "        attn = nn.Softmax(dim=-1)(scores)\n",
    "        context = torch.matmul(attn, V)\n",
    "        return context, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_heads, d_model, d_k, device):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_k\n",
    "        self.W_Q = nn.Linear(d_model, d_k * n_heads)\n",
    "        self.W_K = nn.Linear(d_model, d_k * n_heads)\n",
    "        self.W_V = nn.Linear(d_model, self.d_v * n_heads)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        residual, batch_size = Q, Q.size(0)\n",
    "        q_s = self.W_Q(Q).view(batch_size, -1, self.n_heads, self.d_k).transpose(1,2)\n",
    "        k_s = self.W_K(K).view(batch_size, -1, self.n_heads, self.d_k).transpose(1,2)\n",
    "        v_s = self.W_V(V).view(batch_size, -1, self.n_heads, self.d_v).transpose(1,2)\n",
    "        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.n_heads, 1, 1)\n",
    "        context, attn = ScaledDotProductAttention(self.d_k, self.device)(q_s, k_s, v_s, attn_mask)\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.n_heads * self.d_v)\n",
    "        output = nn.Linear(self.n_heads * self.d_v, self.d_model, device=self.device)(context)\n",
    "        return nn.LayerNorm(self.d_model, device=self.device)(output + residual), attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(F.gelu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "    def __init__(self, n_layers, n_heads, d_model, d_ff, d_k, n_segments, vocab_size, max_len, device):\n",
    "        super(BERT, self).__init__()\n",
    "        self.params = {\n",
    "            'n_layers': n_layers, 'n_heads': n_heads, 'd_model': d_model,\n",
    "            'd_ff': d_ff, 'd_k': d_k, 'n_segments': n_segments,\n",
    "            'vocab_size': vocab_size, 'max_len': max_len\n",
    "        }\n",
    "        self.embedding = Embedding(vocab_size, max_len, n_segments, d_model, device)\n",
    "        self.layers = nn.ModuleList([EncoderLayer(n_heads, d_model, d_ff, d_k, device) for _ in range(n_layers)])\n",
    "        self.fc = nn.Linear(d_model, d_model)\n",
    "        self.activ = nn.Tanh()\n",
    "        self.linear = nn.Linear(d_model, d_model)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.classifier = nn.Linear(d_model, 2)\n",
    "        embed_weight = self.embedding.tok_embed.weight\n",
    "        n_vocab, n_dim = embed_weight.size()\n",
    "        self.decoder = nn.Linear(n_dim, n_vocab, bias=False)\n",
    "        self.decoder.weight = embed_weight\n",
    "        self.decoder_bias = nn.Parameter(torch.zeros(n_vocab))\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, input_ids, segment_ids=None, masked_pos=None, attention_mask=None):\n",
    "        # If segment_ids is not provided, create a default one (all zeros)\n",
    "        if segment_ids is None:\n",
    "            segment_ids = torch.zeros_like(input_ids).to(self.device)\n",
    "        \n",
    "        # If attention_mask is not provided, create a default one\n",
    "        if attention_mask is None:\n",
    "            attention_mask = (input_ids != 0).float().to(self.device)\n",
    "        \n",
    "        # Get embeddings\n",
    "        output = self.embedding(input_ids, segment_ids)\n",
    "        \n",
    "        # Create attention mask using get_attn_pad_mask\n",
    "        enc_self_attn_mask = get_attn_pad_mask(input_ids, input_ids, self.device, attention_mask)\n",
    "        \n",
    "        # Pass through encoder layers\n",
    "        for layer in self.layers:\n",
    "            output, enc_self_attn = layer(output, enc_self_attn_mask)\n",
    "        \n",
    "        # Next Sentence Prediction (NSP)\n",
    "        h_pooled = self.activ(self.fc(output[:, 0]))  # Use the [CLS] token\n",
    "        logits_nsp = self.classifier(h_pooled)\n",
    "        \n",
    "        # Masked Language Modeling (MLM)\n",
    "        if masked_pos is not None:\n",
    "            masked_pos = masked_pos[:, :, None].expand(-1, -1, output.size(-1))\n",
    "            h_masked = torch.gather(output, 1, masked_pos)\n",
    "            h_masked = self.norm(F.gelu(self.linear(h_masked)))\n",
    "            logits_lm = self.decoder(h_masked) + self.decoder_bias\n",
    "        else:\n",
    "            logits_lm = None\n",
    "        \n",
    "        # Return last hidden state along with logits\n",
    "        return output, logits_lm, logits_nsp\n",
    "\n",
    "    def get_last_hidden_state(self, input_ids, segment_ids=None, attention_mask=None):\n",
    "        # If attention_mask is not provided, create a default one\n",
    "        if attention_mask is None:\n",
    "            attention_mask = (input_ids != 0).float().to(self.device)\n",
    "        \n",
    "        # Get embeddings\n",
    "        output = self.embedding(input_ids, segment_ids)\n",
    "        \n",
    "        # Create attention mask using get_attn_pad_mask\n",
    "        enc_self_attn_mask = get_attn_pad_mask(input_ids, input_ids, self.device, attention_mask)\n",
    "        \n",
    "        # Pass through encoder layers\n",
    "        for layer in self.layers:\n",
    "            output, enc_self_attn = layer(output, enc_self_attn_mask)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size of saved model: 23068\n",
      "Embedding vocab size: 23068\n",
      "Tokenizer vocab size: 30522\n"
     ]
    }
   ],
   "source": [
    "# Initialize and load the BERT model from Task 1\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Inspect the saved model's vocabulary size\n",
    "state_dict = torch.load('bert_model.pth', map_location=device)\n",
    "vocab_size_saved = state_dict['embedding.tok_embed.weight'].shape[0]\n",
    "print(\"Vocabulary size of saved model:\", vocab_size_saved)\n",
    "\n",
    "# Use the saved model's vocabulary size\n",
    "vocab_size = vocab_size_saved  # Match the saved model's vocabulary size\n",
    "model = BERT(\n",
    "    n_layers=12,\n",
    "    n_heads=12,\n",
    "    d_model=768,\n",
    "    d_ff=3072,\n",
    "    d_k=64,\n",
    "    n_segments=2,\n",
    "    vocab_size=vocab_size,\n",
    "    max_len=1000,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "# Print embedding vocabulary size\n",
    "print(\"Embedding vocab size:\", model.embedding.tok_embed.num_embeddings)\n",
    "\n",
    "# Load the model weights\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# Debug: Check tokenizer vocabulary size\n",
    "print(\"Tokenizer vocab size:\", tokenizer.vocab_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling\n",
    "SBERT adds a pooling operation to the output of BERT / RoBERTa to derive a fixed sized sentence embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define mean pooling function\n",
    "def mean_pool(token_embeds, attention_mask):\n",
    "    # reshape attention_mask to cover 768-dimension embeddings\n",
    "    in_mask = attention_mask.unsqueeze(-1).expand(\n",
    "        token_embeds.size()\n",
    "    ).float()\n",
    "    # perform mean-pooling but exclude padding tokens (specified by in_mask)\n",
    "    pool = torch.sum(token_embeds * in_mask, 1) / torch.clamp(\n",
    "        in_mask.sum(1), min=1e-9\n",
    "    )\n",
    "    return pool"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Loss Function\n",
    "\n",
    "## Classification Objective Function \n",
    "We concatenate the sentence embeddings $u$ and $v$ with the element-wise difference  $\\lvert u - v \\rvert $ and multiply the result with the trainable weight  $ W_t ∈  \\mathbb{R}^{3n \\times k}  $:\n",
    "\n",
    "$ o = \\text{softmax}\\left(W^T \\cdot \\left(u, v, \\lvert u - v \\rvert\\right)\\right) $\n",
    "\n",
    "where $n$ is the dimension of the sentence embeddings and k the number of labels. We optimize cross-entropy loss. This structure is depicted in Figure 1.\n",
    "\n",
    "## Regression Objective Function. \n",
    "The cosine similarity between the two sentence embeddings $u$ and $v$ is computed (Figure 2). We use means quared-error loss as the objective function.\n",
    "\n",
    "(Manhatten / Euclidean distance, semantically  similar sentences can be found.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configurations(u,v):\n",
    "    # build the |u-v| tensor\n",
    "    uv = torch.sub(u, v)   # batch_size,hidden_dim\n",
    "    uv_abs = torch.abs(uv) # batch_size,hidden_dim\n",
    "    \n",
    "    # concatenate u, v, |u-v|\n",
    "    x = torch.cat([u, v, uv_abs], dim=-1) # batch_size, 3*hidden_dim\n",
    "    return x\n",
    "\n",
    "def cosine_similarity(u, v):\n",
    "    dot_product = torch.sum(u * v, dim=-1)\n",
    "    norm_u = torch.norm(u, dim=-1)\n",
    "    norm_v = torch.norm(v, dim=-1)\n",
    "    similarity = dot_product / (norm_u * norm_v + 1e-9)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_head = torch.nn.Sequential(\n",
    "    torch.nn.Linear(768*3, 512),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(512, 3)\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
    "optimizer_classifier = torch.optim.Adam(classifier_head.parameters(), lr=5e-5)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Setup a warmup for the first ~10% steps\n",
    "total_steps = int(len(raw_dataset) / batch_size)\n",
    "warmup_steps = int(0.1 * total_steps)\n",
    "\n",
    "# Scheduler for the main model optimizer with warmup\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "\t\toptimizer, num_warmup_steps=warmup_steps,\n",
    "  \tnum_training_steps=total_steps - warmup_steps\n",
    ")\n",
    "\n",
    "# Scheduler for the classifier head optimizer with warmup\n",
    "scheduler_classifier = get_linear_schedule_with_warmup(\n",
    "\t\toptimizer_classifier, num_warmup_steps=warmup_steps,\n",
    "  \tnum_training_steps=total_steps - warmup_steps\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e5c46d61a44a359ae1497c1ec67655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Loss: 1.489428\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74235329a42b4409815c2e422b8bd609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Loss: 1.436978\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c3b178fc66b4f08a4b38ff853487bc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Loss: 1.223172\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ded7ae57fd4299b62624e6389ee17e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Loss: 1.393602\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62aace3a77314199babf4d0257c61bba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Loss: 1.720800\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "num_epoch = 5\n",
    "for epoch in range(num_epoch):\n",
    "    model.train()  \n",
    "    classifier_head.train()\n",
    "    for step, batch in enumerate(tqdm(train_dataloader, leave=True)):\n",
    "        optimizer.zero_grad()\n",
    "        optimizer_classifier.zero_grad()\n",
    "        \n",
    "        inputs_ids_a = batch['premise_input_ids'].to(device)\n",
    "        inputs_ids_b = batch['hypothesis_input_ids'].to(device)\n",
    "        attention_a = batch['premise_attention_mask'].to(device)\n",
    "        attention_b = batch['hypothesis_attention_mask'].to(device)\n",
    "        label = batch['labels'].to(device)\n",
    "        \n",
    "        inputs_ids_a = torch.clamp(inputs_ids_a, max=vocab_size - 1)\n",
    "        inputs_ids_b = torch.clamp(inputs_ids_b, max=vocab_size - 1)\n",
    "        \n",
    "        u_last_hidden_state, _, _ = model(inputs_ids_a, attention_mask=attention_a)  \n",
    "        v_last_hidden_state, _, _ = model(inputs_ids_b, attention_mask=attention_b)  \n",
    "\n",
    "        u_mean_pool = mean_pool(u_last_hidden_state, attention_a) \n",
    "        v_mean_pool = mean_pool(v_last_hidden_state, attention_b) \n",
    "        \n",
    "        x = torch.cat([u_mean_pool, v_mean_pool, torch.abs(u_mean_pool - v_mean_pool)], dim=-1) \n",
    "        \n",
    "        x = classifier_head(x) \n",
    "        \n",
    "        loss = criterion(x, label)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer_classifier.step()\n",
    "\n",
    "        scheduler.step() \n",
    "        scheduler_classifier.step()\n",
    "        \n",
    "    print(f'Epoch: {epoch + 1} | Loss: {loss.item():.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e897f1a2ce864b8e8f0eb8c7ffba20dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3420\n",
      "Average Cosine Similarity: 0.9989\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "classifier_head.eval()\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "total_similarity = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "        inputs_ids_a = batch['premise_input_ids'].to(device)\n",
    "        inputs_ids_b = batch['hypothesis_input_ids'].to(device)\n",
    "        attention_a = batch['premise_attention_mask'].to(device)\n",
    "        attention_b = batch['hypothesis_attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        inputs_ids_a = torch.clamp(inputs_ids_a, min=0, max=vocab_size - 1)\n",
    "        inputs_ids_b = torch.clamp(inputs_ids_b, min=0, max=vocab_size - 1)\n",
    "        \n",
    "        u_output, _, _ = model(inputs_ids_a, attention_mask=attention_a)\n",
    "        v_output, _, _ = model(inputs_ids_b, attention_mask=attention_b)\n",
    "        \n",
    "        u_pool = mean_pool(u_output, attention_a)\n",
    "        v_pool = mean_pool(v_output, attention_b)\n",
    "        \n",
    "        x = torch.cat([u_pool, v_pool, torch.abs(u_pool - v_pool)], dim=-1)\n",
    "        logits = classifier_head(x)\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "        total_correct += (preds == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "        \n",
    "        # Calculate cosine similarity\n",
    "        similarity_scores = cosine_similarity(u_pool, v_pool)\n",
    "        total_similarity += similarity_scores.sum().item()\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = total_correct / total_samples\n",
    "average_similarity = total_similarity / total_samples\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Average Cosine Similarity: {average_similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('models/tokenizer/tokenizer_config.json',\n",
       " 'models/tokenizer/special_tokens_map.json',\n",
       " 'models/tokenizer/vocab.txt',\n",
       " 'models/tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create the 'models' directory if it doesn't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Save the BERT model and classifier head\n",
    "torch.save(model.state_dict(), 'models/best_model.pth')\n",
    "torch.save(classifier_head.state_dict(), 'models/classifier_head.pth')\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained('models/tokenizer')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• Premise: A man is playing a guitar on stage.\n",
      "• Hypothesis: The man is performing music.\n",
      "• Label: Entailment\n",
      "• Cosine Similarity: 0.9994\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def predict_label(model, classifier_head, tokenizer, premise, hypothesis, device):\n",
    "    # Tokenize and convert sentences to input IDs and attention masks\n",
    "    inputs_a = tokenizer(premise, return_tensors='pt', truncation=True, padding=True).to(device)\n",
    "    inputs_b = tokenizer(hypothesis, return_tensors='pt', truncation=True, padding=True).to(device)\n",
    "\n",
    "    # Move input IDs and attention masks to the active device\n",
    "    inputs_ids_a = inputs_a['input_ids']\n",
    "    attention_a = inputs_a['attention_mask']\n",
    "    inputs_ids_b = inputs_b['input_ids']\n",
    "    attention_b = inputs_b['attention_mask']\n",
    "\n",
    "    # Extract token embeddings from BERT\n",
    "    u = model(inputs_ids_a, attention_mask=attention_a)[0]  # all token embeddings A = batch_size, seq_len, hidden_dim\n",
    "    v = model(inputs_ids_b, attention_mask=attention_b)[0]  # all token embeddings B = batch_size, seq_len, hidden_dim\n",
    "\n",
    "    # Get the mean-pooled vectors\n",
    "    u_pool = mean_pool(u, attention_a)  # batch_size, hidden_dim\n",
    "    v_pool = mean_pool(v, attention_b)  # batch_size, hidden_dim\n",
    "\n",
    "    # Concatenate embeddings for classification\n",
    "    x = torch.cat([u_pool, v_pool, torch.abs(u_pool - v_pool)], dim=-1)\n",
    "\n",
    "    # Predict label using the classifier head\n",
    "    logits = classifier_head(x)\n",
    "    pred_label = torch.argmax(logits, dim=-1).item()  # Get the predicted label index\n",
    "\n",
    "    # Map label index to text\n",
    "    label_map = {0: \"entailment\", 1: \"neutral\", 2: \"contradiction\"}\n",
    "    predicted_label_text = label_map[pred_label]\n",
    "\n",
    "    return predicted_label_text\n",
    "\n",
    "def calculate_similarity(model, tokenizer, premise, hypothesis, device):\n",
    "    # Tokenize and convert sentences to input IDs and attention masks\n",
    "    inputs_a = tokenizer(premise, return_tensors='pt', truncation=True, padding=True).to(device)\n",
    "    inputs_b = tokenizer(hypothesis, return_tensors='pt', truncation=True, padding=True).to(device)\n",
    "\n",
    "    # Move input IDs and attention masks to the active device\n",
    "    inputs_ids_a = inputs_a['input_ids']\n",
    "    attention_a = inputs_a['attention_mask']\n",
    "    inputs_ids_b = inputs_b['input_ids']\n",
    "    attention_b = inputs_b['attention_mask']\n",
    "\n",
    "    # Extract token embeddings from BERT\n",
    "    u = model(inputs_ids_a, attention_mask=attention_a)[0]  # all token embeddings A = batch_size, seq_len, hidden_dim\n",
    "    v = model(inputs_ids_b, attention_mask=attention_b)[0]  # all token embeddings B = batch_size, seq_len, hidden_dim\n",
    "\n",
    "    # Get the mean-pooled vectors\n",
    "    u_pool = mean_pool(u, attention_a).detach().cpu().numpy().reshape(-1)  # batch_size, hidden_dim\n",
    "    v_pool = mean_pool(v, attention_b).detach().cpu().numpy().reshape(-1)  # batch_size, hidden_dim\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    similarity_score = cosine_similarity(u_pool.reshape(1, -1), v_pool.reshape(1, -1))[0, 0]\n",
    "\n",
    "    return similarity_score\n",
    "\n",
    "def inference(model, classifier_head, tokenizer, premise, hypothesis, device):\n",
    "    # Predict the label\n",
    "    predicted_label = predict_label(model, classifier_head, tokenizer, premise, hypothesis, device)\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    similarity = calculate_similarity(model, tokenizer, premise, hypothesis, device)\n",
    "\n",
    "    print(f\"• Premise: {premise}\")\n",
    "    print(f\"• Hypothesis: {hypothesis}\")\n",
    "    print(f\"• Label: {predicted_label.capitalize()}\")\n",
    "    print(f\"• Cosine Similarity: {similarity:.4f}\")\n",
    "\n",
    "# Example usage:\n",
    "premise = 'A man is playing a guitar on stage.'\n",
    "hypothesis = 'The man is performing music.'\n",
    "inference(model, classifier_head, tokenizer, premise, hypothesis, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
